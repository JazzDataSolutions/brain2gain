# Logstash Pipeline Configuration for Brain2Gain

input {
  # Filebeat input for Docker container logs
  beats {
    port => 5044
  }
  
  # Syslog input for system logs
  syslog {
    port => 5000
    facility_labels => ["kernel", "user-level", "mail", "daemon", "security", "syslogd", "line printer", "network news", "uucp", "clock", "security2", "ftp", "ntp", "logaudit", "logalert", "clock2", "local0", "local1", "local2", "local3", "local4", "local5", "local6", "local7"]
  }
  
  # HTTP input for application logs
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse Docker container logs
  if [docker][container][name] {
    mutate {
      add_field => { "service" => "%{[docker][container][name]}" }
    }
    
    # Parse Brain2Gain backend logs
    if [docker][container][name] =~ /brain2gain.*backend/ {
      grok {
        match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:log_message}" }
      }
      
      # Parse JSON logs if present
      if [log_message] =~ /^\{.*\}$/ {
        json {
          source => "log_message"
          target => "json_data"
        }
      }
      
      # Add application-specific tags
      mutate {
        add_tag => ["brain2gain", "backend", "api"]
        add_field => { "application" => "brain2gain-backend" }
      }
    }
    
    # Parse Brain2Gain frontend logs (Nginx)
    if [docker][container][name] =~ /brain2gain.*frontend/ {
      grok {
        match => { "message" => "%{NGINXACCESS}" }
      }
      
      mutate {
        add_tag => ["brain2gain", "frontend", "nginx"]
        add_field => { "application" => "brain2gain-frontend" }
      }
    }
    
    # Parse PostgreSQL logs
    if [docker][container][name] =~ /brain2gain.*postgres/ {
      grok {
        match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:process_id}\] %{WORD:level}: %{GREEDYDATA:log_message}" }
      }
      
      mutate {
        add_tag => ["brain2gain", "database", "postgresql"]
        add_field => { "application" => "brain2gain-database" }
      }
    }
    
    # Parse Redis logs
    if [docker][container][name] =~ /brain2gain.*redis/ {
      grok {
        match => { "message" => "%{POSINT:process_id}:%{CHAR:role} %{TIMESTAMP_ISO8601:timestamp} %{CHAR:level} %{GREEDYDATA:log_message}" }
      }
      
      mutate {
        add_tag => ["brain2gain", "cache", "redis"]
        add_field => { "application" => "brain2gain-cache" }
      }
    }
    
    # Parse HAProxy logs
    if [docker][container][name] =~ /brain2gain.*loadbalancer/ {
      grok {
        match => { "message" => "%{HAPROXYHTTP}" }
      }
      
      mutate {
        add_tag => ["brain2gain", "loadbalancer", "haproxy"]
        add_field => { "application" => "brain2gain-loadbalancer" }
      }
    }
  }
  
  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
  
  # Normalize log levels
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }
  
  # Add environment information
  mutate {
    add_field => { 
      "environment" => "production"
      "cluster" => "brain2gain-prod"
    }
  }
  
  # Parse IP addresses for geolocation
  if [clientip] {
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }
  
  # Remove sensitive data
  mutate {
    remove_field => [ "password", "token", "secret", "key" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "brain2gain-logs-%{+YYYY.MM.dd}"
    template_name => "brain2gain-logs"
    template => "/usr/share/logstash/templates/brain2gain-template.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  stdout { 
    codec => rubydebug 
  }
}